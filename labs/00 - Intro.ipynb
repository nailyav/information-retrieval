{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95edd0c6-b44e-40d6-9e9c-48f42ddd5207",
   "metadata": {},
   "source": [
    "# 0. Installing course dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae1d575-f278-450f-aa6f-d99e075a79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting annoy~=1.17.0\n",
      "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
      "     |████████████████████████████████| 646 kB 751 kB/s            \n",
      "\u001b[?25hCollecting argparse~=1.4.0\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting bs4~=0.0.1\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting feedparser~=6.0.8\n",
      "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
      "     |████████████████████████████████| 81 kB 2.4 MB/s            \n",
      "\u001b[?25hCollecting hnswlib\n",
      "  Downloading hnswlib-0.6.0.tar.gz (30 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonlines~=3.0.0\n",
      "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "     |████████████████████████████████| 203 kB 4.6 MB/s            \n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "     |████████████████████████████████| 11.2 MB 5.1 MB/s            \n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "     |████████████████████████████████| 1.5 MB 1.2 MB/s            \n",
      "\u001b[?25hCollecting numpy>=1.15\n",
      "  Using cached numpy-1.22.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.6 MB)\n",
      "     |████████████████████████████████| 66.6 MB 238 kB/s            \n",
      "\u001b[?25hCollecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
      "     |████████████████████████████████| 60.4 MB 5.6 MB/s            \n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "     |████████████████████████████████| 11.7 MB 4.9 MB/s            \n",
      "\u001b[?25hCollecting pygtrie~=2.4.2\n",
      "  Downloading pygtrie-2.4.2.tar.gz (35 kB)\n",
      "Collecting requests~=2.25.1\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 4.0 MB/s            \n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "     |████████████████████████████████| 26.4 MB 5.0 MB/s            \n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)\n",
      "     |████████████████████████████████| 39.8 MB 340 kB/s            \n",
      "\u001b[?25hCollecting selenium~=4.1.0\n",
      "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "     |████████████████████████████████| 958 kB 1.3 MB/s            \n",
      "\u001b[?25hCollecting spacy\n",
      "  Downloading spacy-3.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
      "     |████████████████████████████████| 6.1 MB 4.8 MB/s            \n",
      "\u001b[?25hCollecting spacy-transformers\n",
      "  Downloading spacy_transformers-1.1.4-py2.py3-none-any.whl (51 kB)\n",
      "     |████████████████████████████████| 51 kB 365 kB/s            \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "     |████████████████████████████████| 76 kB 3.3 MB/s            \n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 3.9 MB/s            \n",
      "\u001b[?25hCollecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/nailya/.local/lib/python3.9/site-packages (from jsonlines~=3.0.0->-r ../requirements.txt (line 7)) (21.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3.9/site-packages (from requests~=2.25.1->-r ../requirements.txt (line 16)) (2021.10.8)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3.9/site-packages (from requests~=2.25.1->-r ../requirements.txt (line 16)) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests~=2.25.1->-r ../requirements.txt (line 16)) (1.26.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "     |████████████████████████████████| 356 kB 3.6 MB/s            \n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/lib/python3.9/site-packages (from urllib3<1.27,>=1.21.1->requests~=2.25.1->-r ../requirements.txt (line 16)) (20.0.1)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /usr/lib/python3.9/site-packages (from urllib3<1.27,>=1.21.1->requests~=2.25.1->-r ../requirements.txt (line 16)) (35.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/lib/python3.9/site-packages (from cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests~=2.25.1->-r ../requirements.txt (line 16)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests~=2.25.1->-r ../requirements.txt (line 16)) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/lib/python3.9/site-packages (from pyOpenSSL>=0.14->urllib3<1.27,>=1.21.1->requests~=2.25.1->-r ../requirements.txt (line 16)) (1.16.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 4.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from librosa->-r ../requirements.txt (line 8)) (20.9)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/nailya/.local/lib/python3.9/site-packages (from librosa->-r ../requirements.txt (line 8)) (5.1.1)\n",
      "Collecting joblib>=0.14\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     |████████████████████████████████| 306 kB 5.1 MB/s            \n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "     |████████████████████████████████| 323 kB 5.0 MB/s            \n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 3.0 MB/s            \n",
      "\u001b[?25hCollecting soundfile>=0.10.2\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting numba>=0.43.0\n",
      "  Downloading numba-0.55.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 191 kB/s            \n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "     |████████████████████████████████| 377 kB 2.1 MB/s            \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting numpy>=1.15\n",
      "  Downloading numpy-1.21.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "     |████████████████████████████████| 15.7 MB 4.9 MB/s            \n",
      "\u001b[?25hCollecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "     |████████████████████████████████| 34.5 MB 14 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from numba>=0.43.0->librosa->-r ../requirements.txt (line 8)) (57.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.9/site-packages (from packaging>=20.0->librosa->-r ../requirements.txt (line 8)) (2.4.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/lib/python3.9/site-packages (from pooch>=1.0->librosa->-r ../requirements.txt (line 8)) (1.4.4)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 4.1 MB/s            \n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "     |████████████████████████████████| 890 kB 4.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /home/nailya/.local/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 9)) (8.4.0)\n",
      "Requirement already satisfied: click in /home/nailya/.local/lib/python3.9/site-packages (from nltk->-r ../requirements.txt (line 10)) (8.0.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.1.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "     |████████████████████████████████| 763 kB 4.0 MB/s            \n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "     |████████████████████████████████| 503 kB 4.2 MB/s            \n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: jinja2 in /home/nailya/.local/lib/python3.9/site-packages (from spacy->-r ../requirements.txt (line 20)) (3.0.3)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
      "     |████████████████████████████████| 635 kB 2.3 MB/s            \n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "     |████████████████████████████████| 11.3 MB 5.3 MB/s            \n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "     |████████████████████████████████| 128 kB 4.1 MB/s            \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 4.7 MB/s            \n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     |████████████████████████████████| 9.9 MB 268 kB/s            \n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "     |████████████████████████████████| 452 kB 4.5 MB/s            \n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 1.8 MB/s            \n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 3.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/nailya/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->-r ../requirements.txt (line 20)) (4.0.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.10.1-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 11 kB/s              \n",
      "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
      "  Downloading spacy_alignments-0.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 6.6 MB/s            \n",
      "\u001b[?25hCollecting transformers<4.16.0,>=3.4.0\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "     |████████████████████████████████| 3.4 MB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3.9/site-packages (from transformers<4.16.0,>=3.4.0->spacy-transformers->-r ../requirements.txt (line 21)) (5.4.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 6.6 MB/s            \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 6.7 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 2.9 MB/s            \n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nailya/.local/lib/python3.9/site-packages (from jinja2->spacy->-r ../requirements.txt (line 20)) (2.0.1)\n",
      "Using legacy 'setup.py install' for annoy, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pygtrie, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for audioread, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for resampy, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for sgmllib3k, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: hnswlib\n",
      "  Building wheel for hnswlib (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.6.0-cp39-cp39-linux_x86_64.whl size=2026800 sha256=ab55ee9e2c2ab17f00178fbf6483533ed0b2c5a0b96a529f045ee2fbe03c34a1\n",
      "  Stored in directory: /home/nailya/.cache/pip/wheels/8f/fe/b2/22eedd8251b7496bb197f91b674899f0c41eaa94f92e7a0ba9\n",
      "Successfully built hnswlib\n",
      "Installing collected packages: numpy, murmurhash, idna, cymem, catalogue, wasabi, typer, tqdm, srsly, sortedcontainers, sniffio, smart-open, requests, regex, pydantic, preshed, outcome, llvmlite, joblib, h11, filelock, blis, async-generator, wsproto, trio, tokenizers, threadpoolctl, thinc, spacy-loggers, spacy-legacy, soupsieve, scipy, sacremoses, pathy, numba, langcodes, huggingface-hub, trio-websocket, transformers, torch, spacy-alignments, spacy, soundfile, sgmllib3k, scikit-learn, resampy, pytz, pooch, kiwisolver, fonttools, cycler, beautifulsoup4, audioread, spacy-transformers, selenium, pygtrie, pandas, opencv-python, opencv-contrib-python, nltk, matplotlib, librosa, jsonlines, hnswlib, feedparser, bs4, argparse, annoy\n",
      "    Running setup.py install for sgmllib3k ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for resampy ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for audioread ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pygtrie ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for annoy ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed annoy-1.17.0 argparse-1.4.0 async-generator-1.10 audioread-2.1.9 beautifulsoup4-4.10.0 blis-0.7.5 bs4-0.0.1 catalogue-2.0.6 cycler-0.11.0 cymem-2.0.6 feedparser-6.0.8 filelock-3.4.2 fonttools-4.28.5 h11-0.13.0 hnswlib-0.6.0 huggingface-hub-0.4.0 idna-2.10 joblib-1.1.0 jsonlines-3.0.0 kiwisolver-1.3.2 langcodes-3.3.0 librosa-0.8.1 llvmlite-0.38.0 matplotlib-3.5.1 murmurhash-1.0.6 nltk-3.6.7 numba-0.55.0 numpy-1.21.5 opencv-contrib-python-4.5.5.62 opencv-python-4.5.5.62 outcome-1.1.0 pandas-1.4.0 pathy-0.6.1 pooch-1.6.0 preshed-3.0.6 pydantic-1.8.2 pygtrie-2.4.2 pytz-2021.3 regex-2022.1.18 requests-2.25.1 resampy-0.2.2 sacremoses-0.0.47 scikit-learn-1.0.2 scipy-1.7.3 selenium-4.1.0 sgmllib3k-1.0.0 smart-open-5.2.1 sniffio-1.2.0 sortedcontainers-2.4.0 soundfile-0.10.3.post1 soupsieve-2.3.1 spacy-3.2.1 spacy-alignments-0.8.4 spacy-legacy-3.0.8 spacy-loggers-1.0.1 spacy-transformers-1.1.4 srsly-2.4.2 thinc-8.0.13 threadpoolctl-3.0.0 tokenizers-0.10.3 torch-1.10.1 tqdm-4.62.3 transformers-4.15.0 trio-0.19.0 trio-websocket-0.9.2 typer-0.4.0 wasabi-0.9.0 wsproto-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f337db2-7f6a-4520-b51e-f38f064ed599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: conda: command not found\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2f0dd-1d63-412c-ae93-2f012c3d8f0c",
   "metadata": {},
   "source": [
    "Run the next cell if you want to download embedding model, but this is not required during this lab. You can do it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fa01d2-dd4d-48d4-a27b-9ae610d9e7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ No compatible package found for 'en_trf_distilbertbaseuncased_lg'\n",
      "(spaCy v3.2.1)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_trf_distilbertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7bedc-d559-437e-b106-12c860acfbab",
   "metadata": {},
   "source": [
    "# 1. Touching the Internet\n",
    "\n",
    "Solve the following task. Download [this page](https://raw.githubusercontent.com/IUCVLab/information-retrieval/main/datasets/facts.txt), and save it to the file with the name derived from the URL. File with another URL should not be save into the file with this name. E.g. [this file](https://github.com/IUCVLab/information-retrieval/blob/main/datasets/facts.txt).\n",
    "\n",
    "Ref: [requests](https://docs.python-requests.org/en/latest/) library is cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639fb2d7-d577-4ae6-beb4-2487213024cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = f\"https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd\"\n",
    "print(url)\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(url, 'html.parser')\n",
    "for tag in soup.select('user-details > a'):\n",
    "  print(tag.get-text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7601aaf-3534-42cd-bb33-665d2d92c79d",
   "metadata": {},
   "source": [
    "# 2. Parsing different formats\n",
    "\n",
    "Most probably, if you meet something in Internet, this is: binary, plain text, XML, or json. XML also splits into xHTML, RSS, Atom, SOAP, XML-RPC, ... . Your task is to learn, how to process different formats.\n",
    "\n",
    "## 2.1. JSON\n",
    "\n",
    "In [the given file](http://sprotasov.ru/data/postnauka.txt) there is valid json. Parse it and print all video URLs, which have `computer science` tag. Use built-in features of `requests`, or just a `json` library ([ref](https://docs.python.org/3/library/json.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628c2c18-b896-40f9-bac9-2fefc5027da1",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Unexpected UTF-8 BOM (decode using utf-8-sig): line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      6\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[0;32m----> 8\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputer science\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.9/json/__init__.py:335\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\ufeff\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected UTF-8 BOM (decode using utf-8-sig)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m                               s, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unexpected UTF-8 BOM (decode using utf-8-sig): line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "url = 'http://sprotasov.ru/data/postnauka.txt'\n",
    "r = requests.get(url)\n",
    "jsonData = r.content.decode()\n",
    "\n",
    "data = json.loads(jsonData)\n",
    "\n",
    "for tag in data.get('tags'):\n",
    "    if tag == 'computer science':\n",
    "      print(data.get('url'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97530a0-46d4-47e3-a7bb-ca479680007d",
   "metadata": {},
   "source": [
    "## 2.2. HTML\n",
    "\n",
    "For a given StackExchange answer extract logins of the contributors (who asked and who answered) with votes. [bs4](https://beautiful-soup-4.readthedocs.io/en/latest/) will help you to do the job.\n",
    "\n",
    "I can recommend to use CSS or XPath selectors. `div` elements with `post-layout` class represent answers. Inside there are `div` with `votecell` class stroring votes number and `div` with class `user-details` storing user info. My personal recommendation is to use `css selectors`, which are [documented here](https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67db473-a8f0-414c-adbc-ce0e9e4710bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nailya/.local/lib/python3.9/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = f\"https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd\"\n",
    "print(url)\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(url, 'html.parser')\n",
    "for tag in soup.select('user-details > a'):\n",
    "  print(tag.get-text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708766b-0db3-4062-87a1-9ba96c60440b",
   "metadata": {},
   "source": [
    "# 2.3. RSS feed\n",
    "\n",
    "A lot of information is already organized in typed XML documents. Podcasts are just RSS feed. Parse [the feed of this podcast](http://sprotasov.ru/podcast/rss.xml) and print out the time span between the first and the last episodes. Use [`feedparser` for this](https://waylonwalker.com/parsing-rss-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2090f810-d706-4bb2-8c85-d485a48432a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "rss = 'http://sprotasov.ru/podcast/rss.xml'\n",
    "# feedparser.parse(rss) \n",
    "\n",
    "# TODO: complete the code to compute the time span of all the episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a63b1-c106-4a13-8e55-9240e9c8418f",
   "metadata": {},
   "source": [
    "# 3. Solving simple information retrieval task\n",
    "\n",
    "According to the name, `information retrieval` is the discipline, which helps retrieves information (from unstructured sources). Thus, we will retrieve some information from [this news article](https://www.bbc.com/news/world-us-canada-59944889). Your task is to write a code, which will answer the question: **How many people die every day in the US waiting for a transplant?** Write flexible enough code. Test yourself by changing the link to [this one](https://www.americantransplantfoundation.org/about-transplant/facts-and-myths/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7660c706-371b-4050-aede-e4b3e4014ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.bbc.com/news/world-us-canada-59944889'\n",
    "question = 'How many people die every day in the US waiting for a transplant?'\n",
    "\n",
    "# TODO. Impress me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2e9f9-5fea-4909-888e-fa15d2af08d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
